{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import os\n",
    "\n",
    "def csv2dict(file):\n",
    "    dicts = []\n",
    "    with open(file, mode='r') as f:\n",
    "        csv_reader = csv.DictReader(f)\n",
    "        for row in csv_reader:\n",
    "            new_dict = {}\n",
    "            for key, value in row.items():\n",
    "                try:\n",
    "                    new_dict[key] = float(value)\n",
    "                except ValueError:\n",
    "                    new_dict[key] = value\n",
    "            dicts.append(new_dict)\n",
    "    return dicts\n",
    "\n",
    "def load_training_data(features_location, performance_location):\n",
    "    feature_dicts = csv2dict(features_location)\n",
    "    performance_matrix = csv2dict(performance_location)\n",
    "    algorithms = [list(algorithm.keys()) for algorithm in performance_matrix]\n",
    "    return feature_dicts, performance_matrix, algorithms\n",
    "\n",
    "def file_name(file_dir):\n",
    "    for root, dirs, files in os.walk(file_dir):\n",
    "        return files\n",
    "\n",
    "features_locations = file_name(\"data/feature_extraction\")\n",
    "performance_locations = file_name(\"data/performance\")\n",
    "\n",
    "features_locations.sort()\n",
    "performance_locations.sort()\n",
    "\n",
    "X = []\n",
    "y = []\n",
    "\n",
    "for i in range (len(features_locations)):\n",
    "    feature_dicts, performance_matrix, algorithms = load_training_data(\"data/feature_extraction/\"+features_locations[i], \"data/performance/\"+performance_locations[i])\n",
    "    \n",
    "    temp_X = list(feature_dicts[0].values())\n",
    "    temp_X_clean = [0.0 if val == '' else val for val in temp_X]\n",
    "    X.append(temp_X_clean)\n",
    "    \n",
    "    temp_y = list(performance_matrix[0].values())\n",
    "    y.append(temp_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Input, Dense\n",
    "from keras import regularizers\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 308ms/step - loss: 951928949462045556736.0000 - val_loss: 2880785485492740161536.0000\n",
      "Epoch 2/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 951928949462045556736.0000 - val_loss: 2880785485492740161536.0000\n",
      "Epoch 3/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 951929019830789734400.0000 - val_loss: 2880785485492740161536.0000\n",
      "Epoch 4/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 951929019830789734400.0000 - val_loss: 2880785485492740161536.0000\n",
      "Epoch 5/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 951928949462045556736.0000 - val_loss: 2880785485492740161536.0000\n",
      "Epoch 6/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 951928879093301379072.0000 - val_loss: 2880785485492740161536.0000\n",
      "Epoch 7/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 951928949462045556736.0000 - val_loss: 2880785485492740161536.0000\n",
      "Epoch 8/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 951929019830789734400.0000 - val_loss: 2880785485492740161536.0000\n",
      "Epoch 9/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 951928949462045556736.0000 - val_loss: 2880785485492740161536.0000\n",
      "Epoch 10/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 951928949462045556736.0000 - val_loss: 2880785485492740161536.0000\n",
      "Epoch 11/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 951929019830789734400.0000 - val_loss: 2880785485492740161536.0000\n",
      "Epoch 12/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 951929019830789734400.0000 - val_loss: 2880785485492740161536.0000\n",
      "Epoch 13/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 951928949462045556736.0000 - val_loss: 2880785485492740161536.0000\n",
      "Epoch 14/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 951928949462045556736.0000 - val_loss: 2880785485492740161536.0000\n",
      "Epoch 15/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 951929019830789734400.0000 - val_loss: 2880785485492740161536.0000\n",
      "Epoch 16/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - loss: 951929019830789734400.0000 - val_loss: 2880785485492740161536.0000\n",
      "Epoch 17/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - loss: 951928949462045556736.0000 - val_loss: 2880785485492740161536.0000\n",
      "Epoch 18/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 951929019830789734400.0000 - val_loss: 2880785485492740161536.0000\n",
      "Epoch 19/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 951929019830789734400.0000 - val_loss: 2880785485492740161536.0000\n",
      "Epoch 20/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 951928949462045556736.0000 - val_loss: 2880785485492740161536.0000\n",
      "Epoch 21/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 951928949462045556736.0000 - val_loss: 2880785485492740161536.0000\n",
      "Epoch 22/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 951929019830789734400.0000 - val_loss: 2880785485492740161536.0000\n",
      "Epoch 23/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 951928949462045556736.0000 - val_loss: 2880785485492740161536.0000\n",
      "Epoch 24/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 951928949462045556736.0000 - val_loss: 2880785485492740161536.0000\n",
      "Epoch 25/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 951929019830789734400.0000 - val_loss: 2880785485492740161536.0000\n",
      "Epoch 26/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - loss: 951928949462045556736.0000 - val_loss: 2880785485492740161536.0000\n",
      "Epoch 27/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 951928949462045556736.0000 - val_loss: 2880785485492740161536.0000\n",
      "Epoch 28/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 951928949462045556736.0000 - val_loss: 2880785485492740161536.0000\n",
      "Epoch 29/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 951928949462045556736.0000 - val_loss: 2880785485492740161536.0000\n",
      "Epoch 30/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 951929019830789734400.0000 - val_loss: 2880785485492740161536.0000\n",
      "Epoch 31/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 951928879093301379072.0000 - val_loss: 2880785485492740161536.0000\n",
      "Epoch 32/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 951928949462045556736.0000 - val_loss: 2880785485492740161536.0000\n",
      "Epoch 33/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 951928949462045556736.0000 - val_loss: 2880785485492740161536.0000\n",
      "Epoch 34/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 951929019830789734400.0000 - val_loss: 2880785485492740161536.0000\n",
      "Epoch 35/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 951928949462045556736.0000 - val_loss: 2880785485492740161536.0000\n",
      "Epoch 36/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 951928949462045556736.0000 - val_loss: 2880785485492740161536.0000\n",
      "Epoch 37/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 951928949462045556736.0000 - val_loss: 2880785485492740161536.0000\n",
      "Epoch 38/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - loss: 951928949462045556736.0000 - val_loss: 2880785485492740161536.0000\n",
      "Epoch 39/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 951928949462045556736.0000 - val_loss: 2880785485492740161536.0000\n",
      "Epoch 40/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 951928949462045556736.0000 - val_loss: 2880785485492740161536.0000\n",
      "Epoch 41/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 951928949462045556736.0000 - val_loss: 2880785485492740161536.0000\n",
      "Epoch 42/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 951928949462045556736.0000 - val_loss: 2880785485492740161536.0000\n",
      "Epoch 43/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 951928949462045556736.0000 - val_loss: 2880785485492740161536.0000\n",
      "Epoch 44/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 951928949462045556736.0000 - val_loss: 2880785485492740161536.0000\n",
      "Epoch 45/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 951928879093301379072.0000 - val_loss: 2880785485492740161536.0000\n",
      "Epoch 46/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 951928949462045556736.0000 - val_loss: 2880785485492740161536.0000\n",
      "Epoch 47/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 951928949462045556736.0000 - val_loss: 2880785485492740161536.0000\n",
      "Epoch 48/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - loss: 951928949462045556736.0000 - val_loss: 2880785485492740161536.0000\n",
      "Epoch 49/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 951929019830789734400.0000 - val_loss: 2880785485492740161536.0000\n",
      "Epoch 50/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 951928949462045556736.0000 - val_loss: 2880785485492740161536.0000\n",
      "Epoch 51/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 951928949462045556736.0000 - val_loss: 2880785485492740161536.0000\n",
      "Epoch 52/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 951928949462045556736.0000 - val_loss: 2880785485492740161536.0000\n",
      "Epoch 53/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 951928949462045556736.0000 - val_loss: 2880785485492740161536.0000\n",
      "Epoch 54/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 951928949462045556736.0000 - val_loss: 2880785485492740161536.0000\n",
      "Epoch 55/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 951928949462045556736.0000 - val_loss: 2880785485492740161536.0000\n",
      "Epoch 56/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 951929019830789734400.0000 - val_loss: 2880785485492740161536.0000\n",
      "Epoch 57/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - loss: 951928949462045556736.0000 - val_loss: 2880785485492740161536.0000\n",
      "Epoch 58/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 951929019830789734400.0000 - val_loss: 2880785485492740161536.0000\n",
      "Epoch 59/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 951928949462045556736.0000 - val_loss: 2880785485492740161536.0000\n",
      "Epoch 60/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 951928949462045556736.0000 - val_loss: 2880785485492740161536.0000\n",
      "Epoch 61/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 951929019830789734400.0000 - val_loss: 2880785485492740161536.0000\n",
      "Epoch 62/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 951928949462045556736.0000 - val_loss: 2880785485492740161536.0000\n",
      "Epoch 63/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 951928949462045556736.0000 - val_loss: 2880785485492740161536.0000\n",
      "Epoch 64/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 951928949462045556736.0000 - val_loss: 2880785485492740161536.0000\n",
      "Epoch 65/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 951929019830789734400.0000 - val_loss: 2880785485492740161536.0000\n",
      "Epoch 66/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 951928949462045556736.0000 - val_loss: 2880785485492740161536.0000\n",
      "Epoch 67/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - loss: 951928949462045556736.0000 - val_loss: 2880785485492740161536.0000\n",
      "Epoch 68/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 951928949462045556736.0000 - val_loss: 2880785485492740161536.0000\n",
      "Epoch 69/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 951928949462045556736.0000 - val_loss: 2880785485492740161536.0000\n",
      "Epoch 70/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 951928949462045556736.0000 - val_loss: 2880785485492740161536.0000\n",
      "Epoch 71/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 951928879093301379072.0000 - val_loss: 2880785485492740161536.0000\n",
      "Epoch 72/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 951929019830789734400.0000 - val_loss: 2880785485492740161536.0000\n",
      "Epoch 73/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 951929019830789734400.0000 - val_loss: 2880785485492740161536.0000\n",
      "Epoch 74/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 951928879093301379072.0000 - val_loss: 2880785485492740161536.0000\n",
      "Epoch 75/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 951929019830789734400.0000 - val_loss: 2880785485492740161536.0000\n",
      "Epoch 76/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 951928949462045556736.0000 - val_loss: 2880785485492740161536.0000\n",
      "Epoch 77/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 951928949462045556736.0000 - val_loss: 2880785485492740161536.0000\n",
      "Epoch 78/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 951928949462045556736.0000 - val_loss: 2880785485492740161536.0000\n",
      "Epoch 79/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 951928949462045556736.0000 - val_loss: 2880785485492740161536.0000\n",
      "Epoch 80/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 951929019830789734400.0000 - val_loss: 2880785485492740161536.0000\n",
      "Epoch 81/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 951928949462045556736.0000 - val_loss: 2880785485492740161536.0000\n",
      "Epoch 82/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 951928949462045556736.0000 - val_loss: 2880785485492740161536.0000\n",
      "Epoch 83/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 951928949462045556736.0000 - val_loss: 2880785485492740161536.0000\n",
      "Epoch 84/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 951928949462045556736.0000 - val_loss: 2880785485492740161536.0000\n",
      "Epoch 85/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 951928949462045556736.0000 - val_loss: 2880785485492740161536.0000\n",
      "Epoch 86/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 951928949462045556736.0000 - val_loss: 2880785485492740161536.0000\n",
      "Epoch 87/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 951928949462045556736.0000 - val_loss: 2880785485492740161536.0000\n",
      "Epoch 88/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 951928949462045556736.0000 - val_loss: 2880785485492740161536.0000\n",
      "Epoch 89/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 951928949462045556736.0000 - val_loss: 2880785485492740161536.0000\n",
      "Epoch 90/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 951928949462045556736.0000 - val_loss: 2880785485492740161536.0000\n",
      "Epoch 91/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 951928949462045556736.0000 - val_loss: 2880785485492740161536.0000\n",
      "Epoch 92/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 951929019830789734400.0000 - val_loss: 2880785485492740161536.0000\n",
      "Epoch 93/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 951928879093301379072.0000 - val_loss: 2880785485492740161536.0000\n",
      "Epoch 94/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - loss: 951928949462045556736.0000 - val_loss: 2880785485492740161536.0000\n",
      "Epoch 95/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 951928949462045556736.0000 - val_loss: 2880785485492740161536.0000\n",
      "Epoch 96/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 951928949462045556736.0000 - val_loss: 2880785485492740161536.0000\n",
      "Epoch 97/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 951928949462045556736.0000 - val_loss: 2880785485492740161536.0000\n",
      "Epoch 98/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 951929019830789734400.0000 - val_loss: 2880785485492740161536.0000\n",
      "Epoch 99/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 951928949462045556736.0000 - val_loss: 2880785485492740161536.0000\n",
      "Epoch 100/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 951928949462045556736.0000 - val_loss: 2880785485492740161536.0000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n"
     ]
    }
   ],
   "source": [
    "X = np.array(X)\n",
    "y = np.array(y)\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "input_dim = X.shape[1]\n",
    "encoding_dim = 100\n",
    "\n",
    "input_layer = Input(shape=(input_dim,))\n",
    "# encoded = Dense(encoding_dim, activation='relu', activity_regularizer=regularizers.l1(1e-5))(input_layer)\n",
    "encoded = Dense(encoding_dim, activation='relu')(input_layer)\n",
    "decoded = Dense(input_dim, activation='sigmoid')(encoded)\n",
    "\n",
    "autoencoder = Model(inputs=input_layer, outputs=decoded)\n",
    "\n",
    "encoder = Model(inputs=input_layer, outputs=encoded)\n",
    "\n",
    "autoencoder.compile(optimizer='adam', loss='mean_squared_error')\n",
    "\n",
    "autoencoder.fit(X, X, epochs=100, batch_size=256, shuffle=True, validation_split=0.2)\n",
    "\n",
    "X_train_encoded = encoder.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt('X_selected_autoencoder-deep-learning.csv', X_train_encoded, delimiter=',', fmt='%f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-8 {color: black;background-color: white;}#sk-container-id-8 pre{padding: 0;}#sk-container-id-8 div.sk-toggleable {background-color: white;}#sk-container-id-8 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-8 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-8 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-8 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-8 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-8 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-8 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-8 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-8 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-8 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-8 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-8 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-8 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-8 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-8 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-8 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-8 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-8 div.sk-item {position: relative;z-index: 1;}#sk-container-id-8 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-8 div.sk-item::before, #sk-container-id-8 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-8 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-8 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-8 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-8 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-8 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-8 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-8 div.sk-label-container {text-align: center;}#sk-container-id-8 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-8 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-8\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestRegressor(random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" checked><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestRegressor</label><div class=\"sk-toggleable__content\"><pre>RandomForestRegressor(random_state=42)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestRegressor(random_state=42)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "rf = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "rf.fit(X_train_encoded, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prediction(rf, new_features_location, algorithms):\n",
    "    new_feature_dicts = csv2dict(new_features_location)\n",
    "    new_X = [list(new_feature_dict.values()) for new_feature_dict in new_feature_dicts]\n",
    "    new_X_clean = [[0.0 if val == '' else val for val in row] for row in new_X]\n",
    "    new_X_clean = np.array(new_X_clean)\n",
    "    X_test_encoded = encoder.predict(new_X_clean)\n",
    "    \n",
    "    predicted_performance = rf.predict(X_test_encoded)\n",
    "    even_items = predicted_performance[:, ::2]\n",
    "    odd_items = predicted_performance[:, 1::2]\n",
    "    \n",
    "    # Find the best algorithm for MSE and MAE\n",
    "    best_algorithm_mse = np.argmin(even_items)\n",
    "    best_algorithm_mae = np.argmin(odd_items)\n",
    "    \n",
    "    # Find the second best algorithm for MSE and MAE\n",
    "    temp_mse = np.copy(even_items)\n",
    "    temp_mae = np.copy(odd_items)\n",
    "    temp_mse[0][best_algorithm_mse] = np.inf\n",
    "    temp_mae[0][best_algorithm_mae] = np.inf\n",
    "    second_best_algorithm_mse = np.argmin(temp_mse)\n",
    "    second_best_algorithm_mae = np.argmin(temp_mae)\n",
    "    \n",
    "    print('Predicted performance:', predicted_performance)\n",
    "    algorithm = [[], []]\n",
    "    algorithm[0] = algorithms[0][::2]\n",
    "    algorithm[1] = algorithms[0][1::2]\n",
    "\n",
    "    print(\"Predicted MSEs:\", even_items)\n",
    "    print(\"Best algorithm for MSE:\", algorithm[0][best_algorithm_mse])\n",
    "    print(\"Second best algorithm for MSE:\", algorithm[0][second_best_algorithm_mse])\n",
    "    print(\"Predicted MAEs:\", odd_items)\n",
    "    print(\"Best algorithm for MAE:\", algorithm[1][best_algorithm_mae])\n",
    "    print(\"Second best algorithm for MAE:\", algorithm[1][second_best_algorithm_mae])\n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For the `etth1` dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "Predicted performance: [[0.4153  0.41535 0.39156 0.40628 0.42137 0.43005 0.42341 0.43166 0.40896\n",
      "  0.43083 0.49788 0.50026 0.42003 0.43185 0.46686 0.46465 0.47325 0.47291\n",
      "  0.43035 0.44391]]\n",
      "Predicted MSEs: [[0.4153  0.39156 0.42137 0.42341 0.40896 0.49788 0.42003 0.46686 0.47325\n",
      "  0.43035]]\n",
      "Best algorithm for MSE:  GPHT_MSE\n",
      "Second best algorithm for MSE:  SimMTM_MSE\n",
      "Predicted MAEs: [[0.41535 0.40628 0.43005 0.43166 0.43083 0.50026 0.43185 0.46465 0.47291\n",
      "  0.44391]]\n",
      "Best algorithm for MAE:  GPHT_MAE\n",
      "Second best algorithm for MAE:  GPHT'_MAE\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(prediction(rf, \"data/feature_extraction/etth1_96_features.csv\", algorithms))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
      "Predicted performance: [[0.4153  0.41535 0.39156 0.40628 0.42137 0.43005 0.42341 0.43166 0.40896\n",
      "  0.43083 0.49788 0.50026 0.42003 0.43185 0.46686 0.46465 0.47325 0.47291\n",
      "  0.43035 0.44391]]\n",
      "Predicted MSEs: [[0.4153  0.39156 0.42137 0.42341 0.40896 0.49788 0.42003 0.46686 0.47325\n",
      "  0.43035]]\n",
      "Best algorithm for MSE:  GPHT_MSE\n",
      "Second best algorithm for MSE:  SimMTM_MSE\n",
      "Predicted MAEs: [[0.41535 0.40628 0.43005 0.43166 0.43083 0.50026 0.43185 0.46465 0.47291\n",
      "  0.44391]]\n",
      "Best algorithm for MAE:  GPHT_MAE\n",
      "Second best algorithm for MAE:  GPHT'_MAE\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(prediction(rf, \"data/feature_extraction/etth1_192_features.csv\", algorithms))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "Predicted performance: [[0.4153  0.41535 0.39156 0.40628 0.42137 0.43005 0.42341 0.43166 0.40896\n",
      "  0.43083 0.49788 0.50026 0.42003 0.43185 0.46686 0.46465 0.47325 0.47291\n",
      "  0.43035 0.44391]]\n",
      "Predicted MSEs: [[0.4153  0.39156 0.42137 0.42341 0.40896 0.49788 0.42003 0.46686 0.47325\n",
      "  0.43035]]\n",
      "Best algorithm for MSE:  GPHT_MSE\n",
      "Second best algorithm for MSE:  SimMTM_MSE\n",
      "Predicted MAEs: [[0.41535 0.40628 0.43005 0.43166 0.43083 0.50026 0.43185 0.46465 0.47291\n",
      "  0.44391]]\n",
      "Best algorithm for MAE:  GPHT_MAE\n",
      "Second best algorithm for MAE:  GPHT'_MAE\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(prediction(rf, \"data/feature_extraction/etth1_336_features.csv\", algorithms))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step\n",
      "Predicted performance: [[0.43004 0.42488 0.4055  0.4151  0.4363  0.44034 0.43508 0.43816 0.41976\n",
      "  0.43772 0.51644 0.51302 0.43202 0.43922 0.48258 0.4751  0.4943  0.48682\n",
      "  0.44802 0.45758]]\n",
      "Predicted MSEs: [[0.43004 0.4055  0.4363  0.43508 0.41976 0.51644 0.43202 0.48258 0.4943\n",
      "  0.44802]]\n",
      "Best algorithm for MSE:  GPHT_MSE\n",
      "Second best algorithm for MSE:  SimMTM_MSE\n",
      "Predicted MAEs: [[0.42488 0.4151  0.44034 0.43816 0.43772 0.51302 0.43922 0.4751  0.48682\n",
      "  0.45758]]\n",
      "Best algorithm for MAE:  GPHT_MAE\n",
      "Second best algorithm for MAE:  GPHT'_MAE\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(prediction(rf, \"data/feature_extraction/etth1_720_features.csv\", algorithms))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For the `etth2` dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
      "Predicted performance: [[0.39222661 0.40903446 0.38477961 0.40526989 0.39465989 0.41881282\n",
      "  0.38392536 0.41730564 0.38461571 0.40990132 0.42875561 0.44470425\n",
      "  0.37782704 0.41123368 0.41226532 0.43159757 0.41430054 0.44420796\n",
      "  0.51142639 0.4906035 ]]\n",
      "Predicted MSEs: [[0.39222661 0.38477961 0.39465989 0.38392536 0.38461571 0.42875561\n",
      "  0.37782704 0.41226532 0.41430054 0.51142639]]\n",
      "Best algorithm for MSE:  Supervised_PatchTST_MSE\n",
      "Second best algorithm for MSE:  FPT_MSE\n",
      "Predicted MAEs: [[0.40903446 0.40526989 0.41881282 0.41730564 0.40990132 0.44470425\n",
      "  0.41123368 0.43159757 0.44420796 0.4906035 ]]\n",
      "Best algorithm for MAE:  GPHT_MAE\n",
      "Second best algorithm for MAE:  GPHT'_MAE\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(prediction(rf, \"data/feature_extraction/etth2_96_features.csv\", algorithms))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
      "Predicted performance: [[0.39222661 0.40903446 0.38477961 0.40526989 0.39465989 0.41881282\n",
      "  0.38392536 0.41730564 0.38461571 0.40990132 0.42875561 0.44470425\n",
      "  0.37782704 0.41123368 0.41226532 0.43159757 0.41430054 0.44420796\n",
      "  0.51142639 0.4906035 ]]\n",
      "Predicted MSEs: [[0.39222661 0.38477961 0.39465989 0.38392536 0.38461571 0.42875561\n",
      "  0.37782704 0.41226532 0.41430054 0.51142639]]\n",
      "Best algorithm for MSE:  Supervised_PatchTST_MSE\n",
      "Second best algorithm for MSE:  FPT_MSE\n",
      "Predicted MAEs: [[0.40903446 0.40526989 0.41881282 0.41730564 0.40990132 0.44470425\n",
      "  0.41123368 0.43159757 0.44420796 0.4906035 ]]\n",
      "Best algorithm for MAE:  GPHT_MAE\n",
      "Second best algorithm for MAE:  GPHT'_MAE\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(prediction(rf, \"data/feature_extraction/etth2_192_features.csv\", algorithms))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step\n",
      "Predicted performance: [[0.39222661 0.40903446 0.38477961 0.40526989 0.39465989 0.41881282\n",
      "  0.38392536 0.41730564 0.38461571 0.40990132 0.42875561 0.44470425\n",
      "  0.37782704 0.41123368 0.41226532 0.43159757 0.41430054 0.44420796\n",
      "  0.51142639 0.4906035 ]]\n",
      "Predicted MSEs: [[0.39222661 0.38477961 0.39465989 0.38392536 0.38461571 0.42875561\n",
      "  0.37782704 0.41226532 0.41430054 0.51142639]]\n",
      "Best algorithm for MSE:  Supervised_PatchTST_MSE\n",
      "Second best algorithm for MSE:  FPT_MSE\n",
      "Predicted MAEs: [[0.40903446 0.40526989 0.41881282 0.41730564 0.40990132 0.44470425\n",
      "  0.41123368 0.43159757 0.44420796 0.4906035 ]]\n",
      "Best algorithm for MAE:  GPHT_MAE\n",
      "Second best algorithm for MAE:  GPHT'_MAE\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(prediction(rf, \"data/feature_extraction/etth2_336_features.csv\", algorithms))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step\n",
      "Predicted performance: [[0.39222661 0.40903446 0.38477961 0.40526989 0.39465989 0.41881282\n",
      "  0.38392536 0.41730564 0.38461571 0.40990132 0.42875561 0.44470425\n",
      "  0.37782704 0.41123368 0.41226532 0.43159757 0.41430054 0.44420796\n",
      "  0.51142639 0.4906035 ]]\n",
      "Predicted MSEs: [[0.39222661 0.38477961 0.39465989 0.38392536 0.38461571 0.42875561\n",
      "  0.37782704 0.41226532 0.41430054 0.51142639]]\n",
      "Best algorithm for MSE:  Supervised_PatchTST_MSE\n",
      "Second best algorithm for MSE:  FPT_MSE\n",
      "Predicted MAEs: [[0.40903446 0.40526989 0.41881282 0.41730564 0.40990132 0.44470425\n",
      "  0.41123368 0.43159757 0.44420796 0.4906035 ]]\n",
      "Best algorithm for MAE:  GPHT_MAE\n",
      "Second best algorithm for MAE:  GPHT'_MAE\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(prediction(rf, \"data/feature_extraction/etth2_720_features.csv\", algorithms))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For the `ettm1` dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
      "Predicted performance: [[0.37144994 0.38785805 0.36053342 0.38092152 0.33598815 0.37707414\n",
      "  0.34736517 0.38076255 0.35157873 0.3841633  0.37124673 0.39408269\n",
      "  0.35815725 0.38558174 0.36456244 0.39355849 0.43453439 0.42760983\n",
      "  0.35713304 0.38037338]]\n",
      "Predicted MSEs: [[0.37144994 0.36053342 0.33598815 0.34736517 0.35157873 0.37124673\n",
      "  0.35815725 0.36456244 0.43453439 0.35713304]]\n",
      "Best algorithm for MSE:  Self-supervised_PatchTST_MSE\n",
      "Second best algorithm for MSE:  FPT_MSE\n",
      "Predicted MAEs: [[0.38785805 0.38092152 0.37707414 0.38076255 0.3841633  0.39408269\n",
      "  0.38558174 0.39355849 0.42760983 0.38037338]]\n",
      "Best algorithm for MAE:  Self-supervised_PatchTST_MAE\n",
      "Second best algorithm for MAE:  DLinear_MAE\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(prediction(rf, \"data/feature_extraction/ettm1_96_features.csv\", algorithms))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
      "Predicted performance: [[0.37144994 0.38785805 0.36053342 0.38092152 0.33598815 0.37707414\n",
      "  0.34736517 0.38076255 0.35157873 0.3841633  0.37124673 0.39408269\n",
      "  0.35815725 0.38558174 0.36456244 0.39355849 0.43453439 0.42760983\n",
      "  0.35713304 0.38037338]]\n",
      "Predicted MSEs: [[0.37144994 0.36053342 0.33598815 0.34736517 0.35157873 0.37124673\n",
      "  0.35815725 0.36456244 0.43453439 0.35713304]]\n",
      "Best algorithm for MSE:  Self-supervised_PatchTST_MSE\n",
      "Second best algorithm for MSE:  FPT_MSE\n",
      "Predicted MAEs: [[0.38785805 0.38092152 0.37707414 0.38076255 0.3841633  0.39408269\n",
      "  0.38558174 0.39355849 0.42760983 0.38037338]]\n",
      "Best algorithm for MAE:  Self-supervised_PatchTST_MAE\n",
      "Second best algorithm for MAE:  DLinear_MAE\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(prediction(rf, \"data/feature_extraction/ettm1_192_features.csv\", algorithms))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "Predicted performance: [[0.37144994 0.38785805 0.36053342 0.38092152 0.33598815 0.37707414\n",
      "  0.34736517 0.38076255 0.35157873 0.3841633  0.37124673 0.39408269\n",
      "  0.35815725 0.38558174 0.36456244 0.39355849 0.43453439 0.42760983\n",
      "  0.35713304 0.38037338]]\n",
      "Predicted MSEs: [[0.37144994 0.36053342 0.33598815 0.34736517 0.35157873 0.37124673\n",
      "  0.35815725 0.36456244 0.43453439 0.35713304]]\n",
      "Best algorithm for MSE:  Self-supervised_PatchTST_MSE\n",
      "Second best algorithm for MSE:  FPT_MSE\n",
      "Predicted MAEs: [[0.38785805 0.38092152 0.37707414 0.38076255 0.3841633  0.39408269\n",
      "  0.38558174 0.39355849 0.42760983 0.38037338]]\n",
      "Best algorithm for MAE:  Self-supervised_PatchTST_MAE\n",
      "Second best algorithm for MAE:  DLinear_MAE\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(prediction(rf, \"data/feature_extraction/ettm1_336_features.csv\", algorithms))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
      "Predicted performance: [[0.37144994 0.38785805 0.36053342 0.38092152 0.33598815 0.37707414\n",
      "  0.34736517 0.38076255 0.35157873 0.3841633  0.37124673 0.39408269\n",
      "  0.35815725 0.38558174 0.36456244 0.39355849 0.43453439 0.42760983\n",
      "  0.35713304 0.38037338]]\n",
      "Predicted MSEs: [[0.37144994 0.36053342 0.33598815 0.34736517 0.35157873 0.37124673\n",
      "  0.35815725 0.36456244 0.43453439 0.35713304]]\n",
      "Best algorithm for MSE:  Self-supervised_PatchTST_MSE\n",
      "Second best algorithm for MSE:  FPT_MSE\n",
      "Predicted MAEs: [[0.38785805 0.38092152 0.37707414 0.38076255 0.3841633  0.39408269\n",
      "  0.38558174 0.39355849 0.42760983 0.38037338]]\n",
      "Best algorithm for MAE:  Self-supervised_PatchTST_MAE\n",
      "Second best algorithm for MAE:  DLinear_MAE\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(prediction(rf, \"data/feature_extraction/ettm1_720_features.csv\", algorithms))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For the `ettm2` dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
      "Predicted performance: [[0.24511167 0.29934107 0.23287613 0.29234107 0.23742077 0.30500831\n",
      "  0.23464996 0.30516565 0.2326606  0.30103075 0.24848008 0.3145892\n",
      "  0.23954585 0.30789646 0.24235104 0.31105517 0.24980731 0.31480533\n",
      "  0.23886008 0.31469673]]\n",
      "Predicted MSEs: [[0.24511167 0.23287613 0.23742077 0.23464996 0.2326606  0.24848008\n",
      "  0.23954585 0.24235104 0.24980731 0.23886008]]\n",
      "Best algorithm for MSE:  SimMTM_MSE\n",
      "Second best algorithm for MSE:  GPHT_MSE\n",
      "Predicted MAEs: [[0.29934107 0.29234107 0.30500831 0.30516565 0.30103075 0.3145892\n",
      "  0.30789646 0.31105517 0.31480533 0.31469673]]\n",
      "Best algorithm for MAE:  GPHT_MAE\n",
      "Second best algorithm for MAE:  GPHT'_MAE\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(prediction(rf, \"data/feature_extraction/ettm2_96_features.csv\", algorithms))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
      "Predicted performance: [[0.24511167 0.29934107 0.23287613 0.29234107 0.23742077 0.30500831\n",
      "  0.23464996 0.30516565 0.2326606  0.30103075 0.24848008 0.3145892\n",
      "  0.23954585 0.30789646 0.24235104 0.31105517 0.24980731 0.31480533\n",
      "  0.23886008 0.31469673]]\n",
      "Predicted MSEs: [[0.24511167 0.23287613 0.23742077 0.23464996 0.2326606  0.24848008\n",
      "  0.23954585 0.24235104 0.24980731 0.23886008]]\n",
      "Best algorithm for MSE:  SimMTM_MSE\n",
      "Second best algorithm for MSE:  GPHT_MSE\n",
      "Predicted MAEs: [[0.29934107 0.29234107 0.30500831 0.30516565 0.30103075 0.3145892\n",
      "  0.30789646 0.31105517 0.31480533 0.31469673]]\n",
      "Best algorithm for MAE:  GPHT_MAE\n",
      "Second best algorithm for MAE:  GPHT'_MAE\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(prediction(rf, \"data/feature_extraction/ettm2_192_features.csv\", algorithms))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
      "Predicted performance: [[0.24511167 0.29934107 0.23287613 0.29234107 0.23742077 0.30500831\n",
      "  0.23464996 0.30516565 0.2326606  0.30103075 0.24848008 0.3145892\n",
      "  0.23954585 0.30789646 0.24235104 0.31105517 0.24980731 0.31480533\n",
      "  0.23886008 0.31469673]]\n",
      "Predicted MSEs: [[0.24511167 0.23287613 0.23742077 0.23464996 0.2326606  0.24848008\n",
      "  0.23954585 0.24235104 0.24980731 0.23886008]]\n",
      "Best algorithm for MSE:  SimMTM_MSE\n",
      "Second best algorithm for MSE:  GPHT_MSE\n",
      "Predicted MAEs: [[0.29934107 0.29234107 0.30500831 0.30516565 0.30103075 0.3145892\n",
      "  0.30789646 0.31105517 0.31480533 0.31469673]]\n",
      "Best algorithm for MAE:  GPHT_MAE\n",
      "Second best algorithm for MAE:  GPHT'_MAE\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(prediction(rf, \"data/feature_extraction/ettm2_336_features.csv\", algorithms))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step\n",
      "Predicted performance: [[0.24511167 0.29934107 0.23287613 0.29234107 0.23742077 0.30500831\n",
      "  0.23464996 0.30516565 0.2326606  0.30103075 0.24848008 0.3145892\n",
      "  0.23954585 0.30789646 0.24235104 0.31105517 0.24980731 0.31480533\n",
      "  0.23886008 0.31469673]]\n",
      "Predicted MSEs: [[0.24511167 0.23287613 0.23742077 0.23464996 0.2326606  0.24848008\n",
      "  0.23954585 0.24235104 0.24980731 0.23886008]]\n",
      "Best algorithm for MSE:  SimMTM_MSE\n",
      "Second best algorithm for MSE:  GPHT_MSE\n",
      "Predicted MAEs: [[0.29934107 0.29234107 0.30500831 0.30516565 0.30103075 0.3145892\n",
      "  0.30789646 0.31105517 0.31480533 0.31469673]]\n",
      "Best algorithm for MAE:  GPHT_MAE\n",
      "Second best algorithm for MAE:  GPHT'_MAE\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(prediction(rf, \"data/feature_extraction/ettm2_720_features.csv\", algorithms))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gpht",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
