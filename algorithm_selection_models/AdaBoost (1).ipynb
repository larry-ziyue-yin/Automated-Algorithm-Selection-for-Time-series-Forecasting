{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# AS AdaBoost\n",
        "import csv\n",
        "import numpy as np\n",
        "from sklearn.ensemble import AdaBoostRegressor\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error\n",
        "import os\n",
        "\n",
        "\n",
        "# Function to load CSV data into a dictionary\n",
        "def csv2dict(file):\n",
        "    dicts = []\n",
        "    with open(file, mode='r', encoding='utf-8') as f:  # Ensure correct encoding\n",
        "        csv_reader = csv.DictReader(f)\n",
        "        for row in csv_reader:\n",
        "            new_dict = {}\n",
        "            for key, value in row.items():\n",
        "                try:\n",
        "                    new_dict[key] = float(value)  # Convert to float if possible\n",
        "                except ValueError:\n",
        "                    new_dict[key] = value\n",
        "            dicts.append(new_dict)\n",
        "    return dicts\n",
        "\n",
        "\n",
        "# Function to load training data\n",
        "def load_training_data(features_location, performance_location):\n",
        "    feature_dicts = csv2dict(features_location)\n",
        "    performance_matrix = csv2dict(performance_location)\n",
        "    algorithms = [list(algorithm.keys()) for algorithm in performance_matrix]\n",
        "\n",
        "    X = []\n",
        "    y = []\n",
        "\n",
        "    for d, p in zip(feature_dicts, performance_matrix):\n",
        "        # Extract feature values\n",
        "        feature_values = []\n",
        "        for key in d.keys():\n",
        "            if isinstance(d[key], (int, float)):\n",
        "                feature_values.append(float(d[key]))\n",
        "            else:\n",
        "                feature_values.append(0.0)  # Replace non-numeric with 0.0\n",
        "        X.append(feature_values)\n",
        "\n",
        "        # Extract target values\n",
        "        try:\n",
        "            target = float(list(p.values())[0])  # Assume each performance matrix has one value\n",
        "        except (IndexError, ValueError):\n",
        "            target = 0.0  # Handle according to the actual scenario\n",
        "        y.append(target)\n",
        "\n",
        "    X = np.array(X)\n",
        "    y = np.array(y, dtype=float)\n",
        "\n",
        "    return X, y, algorithms\n",
        "\n",
        "\n",
        "# Function to train an AdaBoost regressor\n",
        "def ada_boost_regressor(X_clean, y_clean):\n",
        "    ada = AdaBoostRegressor(n_estimators=100, random_state=42)\n",
        "    ada.fit(X_clean, y_clean)\n",
        "    return ada\n",
        "\n",
        "\n",
        "# Function to make predictions\n",
        "def prediction(model, new_features_location, algorithms):\n",
        "    new_feature_dicts = csv2dict(new_features_location)\n",
        "    new_X = []\n",
        "    for new_feature_dict in new_feature_dicts:\n",
        "        feature_values = []\n",
        "        for key in new_feature_dict.keys():\n",
        "            if isinstance(new_feature_dict[key], (int, float)):\n",
        "                feature_values.append(float(new_feature_dict[key]))\n",
        "            else:\n",
        "                feature_values.append(0.0)  # Replace non-numeric with 0.0\n",
        "        new_X.append(feature_values)\n",
        "\n",
        "    new_X_clean = np.array(new_X)\n",
        "\n",
        "    # Check for valid feature data\n",
        "    if new_X_clean.size == 0:\n",
        "        print(\"No valid features to predict.\")\n",
        "        return None\n",
        "\n",
        "    predicted_performance = model.predict(new_X_clean)\n",
        "    best_algorithm = np.argmin(predicted_performance)\n",
        "\n",
        "    return predicted_performance, algorithms[0][best_algorithm]\n",
        "\n",
        "\n",
        "# Function to get the file names from a directory\n",
        "def file_name(file_dir):\n",
        "    for root, dirs, files in os.walk(file_dir):\n",
        "        return files  # Return files in the first layer only\n",
        "\n",
        "\n",
        "# Main implementation\n",
        "def main():\n",
        "\n",
        "    feature_directory = \"data/feature_extraction\"\n",
        "    performance_directory = \"data/performance\"\n",
        "\n",
        "    features_locations = file_name(feature_directory)\n",
        "    performance_locations = file_name(performance_directory)\n",
        "\n",
        "    features_locations.sort()\n",
        "    performance_locations.sort()\n",
        "\n",
        "    X = []\n",
        "    y = []\n",
        "    algorithms = []\n",
        "\n",
        "    for i in range(len(features_locations)):\n",
        "        features_path = os.path.join(feature_directory, features_locations[i])\n",
        "        performance_path = os.path.join(performance_directory, performance_locations[i])\n",
        "\n",
        "        X_temp, y_temp, algorithms_temp = load_training_data(features_path, performance_path)\n",
        "\n",
        "        X.append(X_temp)\n",
        "        y.append(y_temp)\n",
        "        algorithms = algorithms_temp\n",
        "\n",
        "    # Combine all data\n",
        "    X = np.vstack(X)  # Combine feature arrays\n",
        "    y = np.concatenate(y)  # Combine target values\n",
        "\n",
        "    # Split training and test data\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "    # Train the AdaBoost model\n",
        "    ada_model = ada_boost_regressor(X_train, y_train)\n",
        "\n",
        "    # Predict on the test set\n",
        "    y_pred = ada_model.predict(X_test)\n",
        "\n",
        "    # Calculate MSE\n",
        "    mse = mean_squared_error(y_test, y_pred)\n",
        "    print(f\"Mean Squared Error (MSE) on the test set: {mse}\")\n",
        "\n",
        "    # Predict on new data\n",
        "    new_features_location = \"data/feature_extraction/etth2_336_features.csv\"\n",
        "    predicted_performance, best_algorithm = prediction(ada_model, new_features_location, algorithms)\n",
        "\n",
        "    if predicted_performance is not None:\n",
        "        print(f\"Predicted performance values: {predicted_performance}\")\n",
        "        print(f\"Best algorithm: {best_algorithm}\")\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "id": "urUlb6ppR-zj"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}